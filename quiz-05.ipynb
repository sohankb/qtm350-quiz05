{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f070b06",
   "metadata": {},
   "source": [
    "## Quiz 05 - Parallel Computing, Reproducibility, and Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6142c4",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "This quiz is based on the material covered in lectures 20 to 24. You may use\n",
    "any resources available to you, including the lecture notes and the internet.\n",
    "\n",
    "All the data required for this quiz can be found in the `data` folder within this repository. If you need to recreate the datasets, you can do so by running the Python script included in the `script-data-generation` folder.\n",
    "\n",
    "**Important:** Please start by completing Question 01 to set up the correct Python environment before proceeding with the other questions.\n",
    "\n",
    "This notebook contains the questions you need to answer.\n",
    "If possible, please submit your answers as an `.html` file on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47fa52",
   "metadata": {},
   "source": [
    "### **Question 01: Setting up the Python Environment**\n",
    "\n",
    "Before proceeding with the rest of the quiz, it is important to set up a Python environment with specific package versions to ensure compatibility and reproducibility. This quiz requires **Python 3.10** and the following packages with exact versions:\n",
    "- `dask-sql=2024.5.0`\n",
    "- `dask=2024.4.1`\n",
    "- `ipykernel=6.29.3`\n",
    "- `joblib=1.3.2`\n",
    "- `numpy=1.26.4`\n",
    "- `pandas=2.2.1`\n",
    "\n",
    "You can use tools like `conda`, `pipenv`, or `uv` to manage your environment. If you use conda (recommended), please make sure you **create the environment and install all packages in the same command**. Also include `-c conda-forge` in your command. Make sure to change your current environment to the new environment after creation. \n",
    "\n",
    "Write the terminal commands in the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43dbf581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sohanbellam/anaconda3/envs/qtm350-quiz\n",
      "\n",
      "  added / updated specs:\n",
      "    - dask-sql=2024.5.0\n",
      "    - dask=2024.4.1\n",
      "    - ipykernel=6.29.3\n",
      "    - joblib=1.3.2\n",
      "    - numpy=1.26.4\n",
      "    - pandas=2.2.1\n",
      "    - python=3.10\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _openmp_mutex      conda-forge/osx-arm64::_openmp_mutex-4.5-7_kmp_llvm \n",
      "  annotated-doc      conda-forge/noarch::annotated-doc-0.0.4-pyhcf101f3_0 \n",
      "  annotated-types    conda-forge/noarch::annotated-types-0.7.0-pyhd8ed1ab_1 \n",
      "  anyio              conda-forge/noarch::anyio-4.12.0-pyhcf101f3_0 \n",
      "  appnope            conda-forge/noarch::appnope-0.1.4-pyhd8ed1ab_1 \n",
      "  asttokens          conda-forge/noarch::asttokens-3.0.1-pyhd8ed1ab_0 \n",
      "  aws-c-auth         conda-forge/osx-arm64::aws-c-auth-0.9.1-h8818502_7 \n",
      "  aws-c-cal          conda-forge/osx-arm64::aws-c-cal-0.9.10-hca30140_1 \n",
      "  aws-c-common       conda-forge/osx-arm64::aws-c-common-0.12.5-hc919400_1 \n",
      "  aws-c-compression  conda-forge/osx-arm64::aws-c-compression-0.3.1-h61d5560_8 \n",
      "  aws-c-event-stream conda-forge/osx-arm64::aws-c-event-stream-0.5.6-h18584fc_6 \n",
      "  aws-c-http         conda-forge/osx-arm64::aws-c-http-0.10.7-hcd69b29_4 \n",
      "  aws-c-io           conda-forge/osx-arm64::aws-c-io-0.23.3-h9710c81_3 \n",
      "  aws-c-mqtt         conda-forge/osx-arm64::aws-c-mqtt-0.13.3-ha255ef3_10 \n",
      "  aws-c-s3           conda-forge/osx-arm64::aws-c-s3-0.10.1-hd860258_2 \n",
      "  aws-c-sdkutils     conda-forge/osx-arm64::aws-c-sdkutils-0.2.4-h61d5560_3 \n",
      "  aws-checksums      conda-forge/osx-arm64::aws-checksums-0.2.7-h61d5560_4 \n",
      "  aws-crt-cpp        conda-forge/osx-arm64::aws-crt-cpp-0.35.2-h5596a46_4 \n",
      "  aws-sdk-cpp        conda-forge/osx-arm64::aws-sdk-cpp-1.11.606-h95becb6_7 \n",
      "  azure-core-cpp     conda-forge/osx-arm64::azure-core-cpp-1.16.1-h88fedcc_0 \n",
      "  azure-identity-cpp conda-forge/osx-arm64::azure-identity-cpp-1.13.2-h853621b_1 \n",
      "  azure-storage-blo~ conda-forge/osx-arm64::azure-storage-blobs-cpp-12.15.0-h10d327b_1 \n",
      "  azure-storage-com~ conda-forge/osx-arm64::azure-storage-common-cpp-12.11.0-h7e4aa5d_1 \n",
      "  azure-storage-fil~ conda-forge/osx-arm64::azure-storage-files-datalake-cpp-12.13.0-hb288d13_1 \n",
      "  bokeh              conda-forge/noarch::bokeh-3.8.1-pyhd8ed1ab_0 \n",
      "  brotli-python      conda-forge/osx-arm64::brotli-python-1.2.0-py310h6123dab_1 \n",
      "  bzip2              conda-forge/osx-arm64::bzip2-1.0.8-hd037594_8 \n",
      "  c-ares             conda-forge/osx-arm64::c-ares-1.34.5-h5505292_0 \n",
      "  ca-certificates    conda-forge/noarch::ca-certificates-2025.11.12-hbd8a1cb_0 \n",
      "  certifi            conda-forge/noarch::certifi-2025.11.12-pyhd8ed1ab_0 \n",
      "  cffi               conda-forge/osx-arm64::cffi-2.0.0-py310hf5b66c1_1 \n",
      "  click              conda-forge/noarch::click-8.3.1-pyh8f84b5b_1 \n",
      "  cloudpickle        conda-forge/noarch::cloudpickle-3.1.2-pyhd8ed1ab_0 \n",
      "  comm               conda-forge/noarch::comm-0.2.3-pyhe01879c_0 \n",
      "  contourpy          conda-forge/osx-arm64::contourpy-1.3.2-py310h7f4e7e6_0 \n",
      "  cytoolz            conda-forge/osx-arm64::cytoolz-1.1.0-py310hfe3a0ae_1 \n",
      "  dask               conda-forge/noarch::dask-2024.4.1-pyhd8ed1ab_0 \n",
      "  dask-core          conda-forge/noarch::dask-core-2024.4.1-pyhd8ed1ab_0 \n",
      "  dask-expr          conda-forge/noarch::dask-expr-1.0.11-pyhd8ed1ab_0 \n",
      "  dask-sql           conda-forge/osx-arm64::dask-sql-2024.5.0-py310h8fb3fad_0 \n",
      "  debugpy            conda-forge/osx-arm64::debugpy-1.8.17-py310h7b404bc_0 \n",
      "  decorator          conda-forge/noarch::decorator-5.2.1-pyhd8ed1ab_0 \n",
      "  distributed        conda-forge/noarch::distributed-2024.4.1-pyhd8ed1ab_0 \n",
      "  dnspython          conda-forge/noarch::dnspython-2.8.0-pyhcf101f3_0 \n",
      "  email-validator    conda-forge/noarch::email-validator-2.3.0-pyhd8ed1ab_0 \n",
      "  email_validator    conda-forge/noarch::email_validator-2.3.0-hd8ed1ab_0 \n",
      "  exceptiongroup     conda-forge/noarch::exceptiongroup-1.3.1-pyhd8ed1ab_0 \n",
      "  executing          conda-forge/noarch::executing-2.2.1-pyhd8ed1ab_0 \n",
      "  fastapi            conda-forge/noarch::fastapi-0.123.5-h6c771bf_0 \n",
      "  fastapi-cli        conda-forge/noarch::fastapi-cli-0.0.16-pyhcf101f3_1 \n",
      "  fastapi-core       conda-forge/noarch::fastapi-core-0.123.5-pyhcf101f3_0 \n",
      "  fsspec             conda-forge/noarch::fsspec-2025.12.0-pyhd8ed1ab_0 \n",
      "  gflags             conda-forge/osx-arm64::gflags-2.2.2-hf9b8971_1005 \n",
      "  glog               conda-forge/osx-arm64::glog-0.7.1-heb240a5_0 \n",
      "  h11                conda-forge/noarch::h11-0.16.0-pyhd8ed1ab_0 \n",
      "  h2                 conda-forge/noarch::h2-4.3.0-pyhcf101f3_0 \n",
      "  hpack              conda-forge/noarch::hpack-4.1.0-pyhd8ed1ab_0 \n",
      "  httpcore           conda-forge/noarch::httpcore-1.0.9-pyh29332c3_0 \n",
      "  httptools          conda-forge/osx-arm64::httptools-0.7.1-py310hfe3a0ae_1 \n",
      "  httpx              conda-forge/noarch::httpx-0.28.1-pyhd8ed1ab_0 \n",
      "  hyperframe         conda-forge/noarch::hyperframe-6.1.0-pyhd8ed1ab_0 \n",
      "  idna               conda-forge/noarch::idna-3.11-pyhd8ed1ab_0 \n",
      "  importlib-metadata conda-forge/noarch::importlib-metadata-8.7.0-pyhe01879c_1 \n",
      "  importlib_metadata conda-forge/noarch::importlib_metadata-8.7.0-h40b2b14_1 \n",
      "  ipykernel          conda-forge/noarch::ipykernel-6.29.3-pyh3cd1d5f_0 \n",
      "  ipython            conda-forge/noarch::ipython-8.37.0-pyh8f84b5b_0 \n",
      "  jedi               conda-forge/noarch::jedi-0.19.2-pyhd8ed1ab_1 \n",
      "  jinja2             conda-forge/noarch::jinja2-3.1.6-pyhcf101f3_1 \n",
      "  joblib             conda-forge/noarch::joblib-1.3.2-pyhd8ed1ab_0 \n",
      "  jupyter_client     conda-forge/noarch::jupyter_client-8.6.3-pyhd8ed1ab_1 \n",
      "  jupyter_core       conda-forge/noarch::jupyter_core-5.9.1-pyhc90fa1f_0 \n",
      "  krb5               conda-forge/osx-arm64::krb5-1.21.3-h237132a_0 \n",
      "  lcms2              conda-forge/osx-arm64::lcms2-2.17-h7eeda09_0 \n",
      "  lerc               conda-forge/osx-arm64::lerc-4.0.0-hd64df32_1 \n",
      "  libabseil          conda-forge/osx-arm64::libabseil-20250512.1-cxx17_hd41c47c_0 \n",
      "  libarrow           conda-forge/osx-arm64::libarrow-22.0.0-h4a3aeba_4_cpu \n",
      "  libarrow-acero     conda-forge/osx-arm64::libarrow-acero-22.0.0-hc317990_4_cpu \n",
      "  libarrow-compute   conda-forge/osx-arm64::libarrow-compute-22.0.0-h75845d1_4_cpu \n",
      "  libarrow-dataset   conda-forge/osx-arm64::libarrow-dataset-22.0.0-hc317990_4_cpu \n",
      "  libarrow-substrait conda-forge/osx-arm64::libarrow-substrait-22.0.0-h144af7f_4_cpu \n",
      "  libblas            conda-forge/osx-arm64::libblas-3.11.0-3_h51639a9_openblas \n",
      "  libbrotlicommon    conda-forge/osx-arm64::libbrotlicommon-1.2.0-hc919400_1 \n",
      "  libbrotlidec       conda-forge/osx-arm64::libbrotlidec-1.2.0-hc919400_1 \n",
      "  libbrotlienc       conda-forge/osx-arm64::libbrotlienc-1.2.0-hc919400_1 \n",
      "  libcblas           conda-forge/osx-arm64::libcblas-3.11.0-3_hb0561ab_openblas \n",
      "  libcrc32c          conda-forge/osx-arm64::libcrc32c-1.1.2-hbdafb3b_0 \n",
      "  libcurl            conda-forge/osx-arm64::libcurl-8.17.0-hdece5d2_0 \n",
      "  libcxx             conda-forge/osx-arm64::libcxx-21.1.7-hf598326_0 \n",
      "  libdeflate         conda-forge/osx-arm64::libdeflate-1.25-hc11a715_0 \n",
      "  libedit            conda-forge/osx-arm64::libedit-3.1.20250104-pl5321hafb1f1b_0 \n",
      "  libev              conda-forge/osx-arm64::libev-4.33-h93a5062_2 \n",
      "  libevent           conda-forge/osx-arm64::libevent-2.1.12-h2757513_1 \n",
      "  libexpat           conda-forge/osx-arm64::libexpat-2.7.3-haf25636_0 \n",
      "  libffi             conda-forge/osx-arm64::libffi-3.5.2-he5f378a_0 \n",
      "  libfreetype        conda-forge/osx-arm64::libfreetype-2.14.1-hce30654_0 \n",
      "  libfreetype6       conda-forge/osx-arm64::libfreetype6-2.14.1-h6da58f4_0 \n",
      "  libgcc             conda-forge/osx-arm64::libgcc-15.2.0-hcbb3090_14 \n",
      "  libgfortran        conda-forge/osx-arm64::libgfortran-15.2.0-h07b0088_14 \n",
      "  libgfortran5       conda-forge/osx-arm64::libgfortran5-15.2.0-hdae7583_14 \n",
      "  libgoogle-cloud    conda-forge/osx-arm64::libgoogle-cloud-2.39.0-head0a95_0 \n",
      "  libgoogle-cloud-s~ conda-forge/osx-arm64::libgoogle-cloud-storage-2.39.0-hfa3a374_0 \n",
      "  libgrpc            conda-forge/osx-arm64::libgrpc-1.73.1-h3063b79_1 \n",
      "  libiconv           conda-forge/osx-arm64::libiconv-1.18-h23cfdf5_2 \n",
      "  libjpeg-turbo      conda-forge/osx-arm64::libjpeg-turbo-3.1.2-hc919400_0 \n",
      "  liblapack          conda-forge/osx-arm64::liblapack-3.11.0-3_hd9741b5_openblas \n",
      "  liblzma            conda-forge/osx-arm64::liblzma-5.8.1-h39f12f2_2 \n",
      "  libnghttp2         conda-forge/osx-arm64::libnghttp2-1.67.0-hc438710_0 \n",
      "  libopenblas        conda-forge/osx-arm64::libopenblas-0.3.30-openmp_ha158390_3 \n",
      "  libopentelemetry-~ conda-forge/osx-arm64::libopentelemetry-cpp-1.21.0-he15edb5_1 \n",
      "  libopentelemetry-~ conda-forge/osx-arm64::libopentelemetry-cpp-headers-1.21.0-hce30654_1 \n",
      "  libparquet         conda-forge/osx-arm64::libparquet-22.0.0-h0ac143b_4_cpu \n",
      "  libpng             conda-forge/osx-arm64::libpng-1.6.51-hfab5511_0 \n",
      "  libprotobuf        conda-forge/osx-arm64::libprotobuf-6.31.1-h658db43_2 \n",
      "  libre2-11          conda-forge/osx-arm64::libre2-11-2025.11.05-h91c62da_0 \n",
      "  libsodium          conda-forge/osx-arm64::libsodium-1.0.20-h99b78c6_0 \n",
      "  libsqlite          conda-forge/osx-arm64::libsqlite-3.51.1-h9a5124b_0 \n",
      "  libssh2            conda-forge/osx-arm64::libssh2-1.11.1-h1590b86_0 \n",
      "  libthrift          conda-forge/osx-arm64::libthrift-0.22.0-h14a376c_1 \n",
      "  libtiff            conda-forge/osx-arm64::libtiff-4.7.1-h4030677_1 \n",
      "  libutf8proc        conda-forge/osx-arm64::libutf8proc-2.11.2-hd2415e0_0 \n",
      "  libuv              conda-forge/osx-arm64::libuv-1.51.0-h6caf38d_1 \n",
      "  libwebp-base       conda-forge/osx-arm64::libwebp-base-1.6.0-h07db88b_0 \n",
      "  libxcb             conda-forge/osx-arm64::libxcb-1.17.0-hdb1d25a_0 \n",
      "  libxml2            conda-forge/osx-arm64::libxml2-2.15.1-hba2cd1d_0 \n",
      "  libxml2-16         conda-forge/osx-arm64::libxml2-16-2.15.1-h8eac4d7_0 \n",
      "  libzlib            conda-forge/osx-arm64::libzlib-1.3.1-h8359307_2 \n",
      "  llvm-openmp        conda-forge/osx-arm64::llvm-openmp-21.1.7-h4a912ad_0 \n",
      "  locket             conda-forge/noarch::locket-1.0.0-pyhd8ed1ab_0 \n",
      "  lz4                conda-forge/osx-arm64::lz4-4.4.5-py310h36fcd3f_0 \n",
      "  lz4-c              conda-forge/osx-arm64::lz4-c-1.10.0-h286801f_1 \n",
      "  markdown-it-py     conda-forge/noarch::markdown-it-py-4.0.0-pyhd8ed1ab_0 \n",
      "  markupsafe         conda-forge/osx-arm64::markupsafe-3.0.3-py310hf4fd40f_0 \n",
      "  matplotlib-inline  conda-forge/noarch::matplotlib-inline-0.2.1-pyhd8ed1ab_0 \n",
      "  mdurl              conda-forge/noarch::mdurl-0.1.2-pyhd8ed1ab_1 \n",
      "  msgpack-python     conda-forge/osx-arm64::msgpack-python-1.1.2-py310h0e897d2_1 \n",
      "  narwhals           conda-forge/noarch::narwhals-2.13.0-pyhcf101f3_0 \n",
      "  ncurses            conda-forge/osx-arm64::ncurses-6.5-h5e97a16_3 \n",
      "  nest-asyncio       conda-forge/noarch::nest-asyncio-1.6.0-pyhd8ed1ab_1 \n",
      "  nlohmann_json      conda-forge/osx-arm64::nlohmann_json-3.12.0-h248ca61_1 \n",
      "  numpy              conda-forge/osx-arm64::numpy-1.26.4-py310hd45542a_0 \n",
      "  openjpeg           conda-forge/osx-arm64::openjpeg-2.5.4-hbfb3c88_0 \n",
      "  openssl            conda-forge/osx-arm64::openssl-3.6.0-h5503f6c_0 \n",
      "  orc                conda-forge/osx-arm64::orc-2.2.1-h4fd0076_0 \n",
      "  packaging          conda-forge/noarch::packaging-25.0-pyh29332c3_1 \n",
      "  pandas             conda-forge/osx-arm64::pandas-2.2.1-py310h401b61c_0 \n",
      "  parso              conda-forge/noarch::parso-0.8.5-pyhcf101f3_0 \n",
      "  partd              conda-forge/noarch::partd-1.4.2-pyhd8ed1ab_0 \n",
      "  pexpect            conda-forge/noarch::pexpect-4.9.0-pyhd8ed1ab_1 \n",
      "  pickleshare        conda-forge/noarch::pickleshare-0.7.5-pyhd8ed1ab_1004 \n",
      "  pillow             conda-forge/osx-arm64::pillow-12.0.0-py310hce4cfee_2 \n",
      "  pip                conda-forge/noarch::pip-25.3-pyh8b19718_0 \n",
      "  platformdirs       conda-forge/noarch::platformdirs-4.5.0-pyhcf101f3_0 \n",
      "  prometheus-cpp     conda-forge/osx-arm64::prometheus-cpp-1.3.0-h0967b3e_0 \n",
      "  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.52-pyha770c72_0 \n",
      "  psutil             conda-forge/osx-arm64::psutil-7.1.3-py310hf151d32_0 \n",
      "  pthread-stubs      conda-forge/osx-arm64::pthread-stubs-0.4-hd74edd7_1002 \n",
      "  ptyprocess         conda-forge/noarch::ptyprocess-0.7.0-pyhd8ed1ab_1 \n",
      "  pure_eval          conda-forge/noarch::pure_eval-0.2.3-pyhd8ed1ab_1 \n",
      "  pyarrow            conda-forge/osx-arm64::pyarrow-22.0.0-py310hb6292c7_0 \n",
      "  pyarrow-core       conda-forge/osx-arm64::pyarrow-core-22.0.0-py310h6cc04f2_0_cpu \n",
      "  pyarrow-hotfix     conda-forge/noarch::pyarrow-hotfix-0.7-pyhd8ed1ab_0 \n",
      "  pycparser          conda-forge/noarch::pycparser-2.22-pyh29332c3_1 \n",
      "  pydantic           conda-forge/noarch::pydantic-2.12.5-pyhcf101f3_1 \n",
      "  pydantic-core      conda-forge/osx-arm64::pydantic-core-2.41.5-py310hf3301a5_1 \n",
      "  pygments           conda-forge/noarch::pygments-2.19.2-pyhd8ed1ab_0 \n",
      "  pysocks            conda-forge/noarch::pysocks-1.7.1-pyha55dd90_7 \n",
      "  python             conda-forge/osx-arm64::python-3.10.19-hcd7f573_2_cpython \n",
      "  python-dateutil    conda-forge/noarch::python-dateutil-2.9.0.post0-pyhe01879c_2 \n",
      "  python-dotenv      conda-forge/noarch::python-dotenv-1.2.1-pyhcf101f3_0 \n",
      "  python-multipart   conda-forge/noarch::python-multipart-0.0.20-pyhff2d567_0 \n",
      "  python-tzdata      conda-forge/noarch::python-tzdata-2025.2-pyhd8ed1ab_0 \n",
      "  python_abi         conda-forge/noarch::python_abi-3.10-8_cp310 \n",
      "  pytz               conda-forge/noarch::pytz-2025.2-pyhd8ed1ab_0 \n",
      "  pyyaml             conda-forge/osx-arm64::pyyaml-6.0.3-py310hf4fd40f_0 \n",
      "  pyzmq              conda-forge/osx-arm64::pyzmq-27.1.0-py310hc4a7dca_0 \n",
      "  re2                conda-forge/osx-arm64::re2-2025.11.05-h64b956e_0 \n",
      "  readline           conda-forge/osx-arm64::readline-8.2-h1d1bf99_2 \n",
      "  rich               conda-forge/noarch::rich-14.2.0-pyhcf101f3_0 \n",
      "  rich-toolkit       conda-forge/noarch::rich-toolkit-0.17.0-pyhcf101f3_0 \n",
      "  setuptools         conda-forge/noarch::setuptools-80.9.0-pyhff2d567_0 \n",
      "  shellingham        conda-forge/noarch::shellingham-1.5.4-pyhd8ed1ab_2 \n",
      "  six                conda-forge/noarch::six-1.17.0-pyhe01879c_1 \n",
      "  snappy             conda-forge/osx-arm64::snappy-1.2.2-hada39a4_1 \n",
      "  sniffio            conda-forge/noarch::sniffio-1.3.1-pyhd8ed1ab_2 \n",
      "  sortedcontainers   conda-forge/noarch::sortedcontainers-2.4.0-pyhd8ed1ab_1 \n",
      "  stack_data         conda-forge/noarch::stack_data-0.6.3-pyhd8ed1ab_1 \n",
      "  starlette          conda-forge/noarch::starlette-0.50.0-pyhfdc7a7d_0 \n",
      "  tabulate           conda-forge/noarch::tabulate-0.9.0-pyhd8ed1ab_2 \n",
      "  tblib              conda-forge/noarch::tblib-3.2.2-pyhcf101f3_0 \n",
      "  tk                 conda-forge/osx-arm64::tk-8.6.13-h892fb3f_3 \n",
      "  tomli              conda-forge/noarch::tomli-2.3.0-pyhcf101f3_0 \n",
      "  toolz              conda-forge/noarch::toolz-1.1.0-pyhd8ed1ab_1 \n",
      "  tornado            conda-forge/osx-arm64::tornado-6.5.2-py310hfe3a0ae_2 \n",
      "  traitlets          conda-forge/noarch::traitlets-5.14.3-pyhd8ed1ab_1 \n",
      "  typer              conda-forge/noarch::typer-0.20.0-pyhefaf540_1 \n",
      "  typer-slim         conda-forge/noarch::typer-slim-0.20.0-pyhcf101f3_1 \n",
      "  typer-slim-standa~ conda-forge/noarch::typer-slim-standard-0.20.0-h4daf872_1 \n",
      "  typing-extensions  conda-forge/noarch::typing-extensions-4.15.0-h396c80c_0 \n",
      "  typing-inspection  conda-forge/noarch::typing-inspection-0.4.2-pyhd8ed1ab_1 \n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-4.15.0-pyhcf101f3_0 \n",
      "  tzdata             conda-forge/noarch::tzdata-2025b-h78e105d_0 \n",
      "  tzlocal            conda-forge/noarch::tzlocal-5.3.1-pyh8f84b5b_0 \n",
      "  urllib3            conda-forge/noarch::urllib3-2.5.0-pyhd8ed1ab_0 \n",
      "  uvicorn            conda-forge/noarch::uvicorn-0.38.0-pyh31011fe_0 \n",
      "  uvicorn-standard   conda-forge/noarch::uvicorn-standard-0.38.0-h31011fe_0 \n",
      "  uvloop             conda-forge/osx-arm64::uvloop-0.22.1-py310hfe3a0ae_1 \n",
      "  watchfiles         conda-forge/osx-arm64::watchfiles-1.1.1-py310h53169e7_0 \n",
      "  wcwidth            conda-forge/noarch::wcwidth-0.2.14-pyhd8ed1ab_0 \n",
      "  websockets         conda-forge/osx-arm64::websockets-15.0.1-py310h2ee35b4_2 \n",
      "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
      "  xorg-libxau        conda-forge/osx-arm64::xorg-libxau-1.0.12-hc919400_1 \n",
      "  xorg-libxdmcp      conda-forge/osx-arm64::xorg-libxdmcp-1.1.5-hc919400_1 \n",
      "  xyzservices        conda-forge/noarch::xyzservices-2025.11.0-pyhd8ed1ab_0 \n",
      "  yaml               conda-forge/osx-arm64::yaml-0.2.5-h925e9cb_3 \n",
      "  zeromq             conda-forge/osx-arm64::zeromq-4.3.5-h888dc83_9 \n",
      "  zict               conda-forge/noarch::zict-3.0.0-pyhd8ed1ab_1 \n",
      "  zipp               conda-forge/noarch::zipp-3.23.0-pyhcf101f3_1 \n",
      "  zlib               conda-forge/osx-arm64::zlib-1.3.1-h8359307_2 \n",
      "  zlib-ng            conda-forge/osx-arm64::zlib-ng-2.3.2-h248ca61_0 \n",
      "  zstandard          conda-forge/osx-arm64::zstandard-0.25.0-py310hf151d32_1 \n",
      "  zstd               conda-forge/osx-arm64::zstd-1.5.7-hbf9d68e_6 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate qtm350-quiz\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Please write your bash commands here. You can run them using the `!` opera#or or the `%%bash` magic.\n",
    "#!/bin/bash\n",
    "# Question 01: Setting up the Python Environment\n",
    "\n",
    "# Create conda environment with Python 3.10 and all required packages\n",
    "!conda create -n qtm350-quiz python=3.10 dask-sql=2024.5.0 dask=2024.4.1 ipykernel=6.29.3 joblib=1.3.2 numpy=1.26.4 pandas=2.2.1 -c conda-forge -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8e018",
   "metadata": {},
   "source": [
    "### Question 02: Understanding the `map` Function and Parallelism\n",
    "\n",
    "The built-in Python `map()` function applies a function to each element sequentially. Using `joblib`, rewrite the following serial code to run in parallel using **all available cores** (hint: use `n_jobs=-1`). Compare the results to verify correctness.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def cube_root(x):\n",
    "    return x ** (1/3)\n",
    "\n",
    "numbers = np.arange(1, 500001)\n",
    "\n",
    "# Serial version using map\n",
    "serial_result = list(map(cube_root, numbers))\n",
    "print(\"First 5 serial results:\", serial_result[:5])\n",
    "```\n",
    "\n",
    "Write the parallel version using `joblib.Parallel` and `delayed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12eea799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 serial results: [1.0, 1.2599210498948732, 1.4422495703074083, 1.5874010519681994, 1.7099759466766968]\n",
      "First 5 serial results: [1.0, 1.2599210498948732, 1.4422495703074083, 1.5874010519681994, 1.7099759466766968]\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "def cube_root(x):\n",
    "    return x ** (1/3)\n",
    "\n",
    "numbers = np.arange(1, 500001)\n",
    "\n",
    "# Serial version using map\n",
    "serial_result = list(map(cube_root, numbers))\n",
    "print(\"First 5 serial results:\", serial_result[:5])\n",
    "\n",
    "# Parallel version\n",
    "parallel_result = Parallel(n_jobs=-1)(delayed(cube_root)(x) for x in numbers)\n",
    "print(\"First 5 serial results:\", parallel_result[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef94ca03",
   "metadata": {},
   "source": [
    "### Question 03: Measuring Parallel Speedup\n",
    "\n",
    "Create a function called `simulate_computation` that generates 100,000 random numbers and calculates their variance. Using `%timeit`, measure and compare the execution time of:\n",
    "\n",
    "1. Running the function **4 times sequentially** in a list comprehension (`[simulate_computation() for _ in range(4)]`)\n",
    "2. Running the function **4 times in parallel** using `joblib` with 4 workers\n",
    "\n",
    "Print and compare both timing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ddaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.56 ms ± 32.7 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "12.5 ms ± 803 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "def simulate_computation():\n",
    "    random = np.random.rand(100000)\n",
    "    return np.var(random)\n",
    "\n",
    "%timeit [simulate_computation() for _ in range(4)]\n",
    "%timeit Parallel(n_jobs=4)(delayed(simulate_computation)() for _ in range(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47889840",
   "metadata": {},
   "source": [
    "### Question 04: Dask Array with Custom Chunk Sizes\n",
    "\n",
    "Create a Dask array of shape (5000, 2000) filled with random integers between 1 and 100. Use chunks of size (500, 500). Then:\n",
    "\n",
    "1. Compute the sum of each row\n",
    "2. Calculate the mean and standard deviation of the entire array\n",
    "3. Print all three results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd325641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-106.94014744   22.15236202   94.29809625 ...   55.98980573   67.61376916\n",
      "  -21.97533284]\n",
      "-2.5124455113762817e-05\n",
      "1.000115364869338\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "import dask.array as da\n",
    "\n",
    "data = np.random.normal(size=10000000).reshape(5000,2000)\n",
    "a = da.from_array(data, chunks=(500,500))\n",
    "\n",
    "print(a.sum(axis=1).compute())\n",
    "print(a.mean().compute())\n",
    "print(a.std().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be770baf",
   "metadata": {},
   "source": [
    "### Question 05: Optimising Chunk Size\n",
    "\n",
    "The chunk size significantly affects Dask performance. Create a Dask array with 100,000 random numbers and test three different chunk sizes: 1,000 (many small chunks), 10,000 (medium chunks), and 50,000 (few large chunks).\n",
    "\n",
    "For each configuration, measure the time to compute `mean(sin(x) + cos(x))`. Which chunk size performed best? Explain why in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5163e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 ms ± 266 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "4.71 ms ± 128 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3.66 ms ± 51.9 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "data = np.random.random(size=100000)\n",
    "\n",
    "# 1,000 chunk\n",
    "a = da.from_array(data, chunks=(1000))\n",
    "%timeit (da.sin(a) + da.cos(a)).mean().compute()\n",
    "\n",
    "# 10,000 chunk\n",
    "a = da.from_array(data, chunks=(10000))\n",
    "%timeit (da.sin(a) + da.cos(a)).mean().compute()\n",
    "\n",
    "# 50,000 chunk\n",
    "a = da.from_array(data, chunks=(50000))\n",
    "%timeit (da.sin(a) + da.cos(a)).mean().compute()\n",
    "\n",
    "# The chunk that performed best was the 50,000 chunk.\n",
    "# It performed best because less resources were spent on\n",
    "# breaking up into many many chunks as opposed to just\n",
    "# two chunks since 100,000 / 50,000 = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f620cfde",
   "metadata": {},
   "source": [
    "### Question 06: Reading Parquet Files with Column Selection\n",
    "\n",
    "The `data` folder contains Parquet files for multiple countries. Using Dask, read **all Parquet files at once** (`data/*.parquet`), but load only the `year` and `population` columns.\n",
    "\n",
    "Calculate the total world population for each year across all countries and display the results sorted by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24cc3239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2022    1985837056\n",
      "2023    1980706538\n",
      "2020    1959057915\n",
      "2018    1940659483\n",
      "2021    1928046753\n",
      "2017    1906082434\n",
      "2019    1893887207\n",
      "2015    1872433473\n",
      "2016    1847205000\n",
      "2014    1824069730\n",
      "Name: population, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "import dask.dataframe as dd\n",
    "df = dd.read_parquet('data/*.parquet', columns = ['year', 'population'])\n",
    "\n",
    "pop = df.groupby('year').population.sum().compute()\n",
    "print(pop.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c5b75",
   "metadata": {},
   "source": [
    "### Question 07: Dask SQL with Multiple Conditions\n",
    "\n",
    "Load the `data.csv` file into a Dask DataFrame and register it as a SQL table. Write a SQL query that:\n",
    "\n",
    "1. Selects countries where `gdp_per_capita` was between 10000 and 50000\n",
    "2. Filters for years between 2000 and 2020\n",
    "3. Orders results by `gdp_per_capita` in descending order\n",
    "4. Limits to the top 2 results\n",
    "\n",
    "Execute the query and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32507297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    country  year  gdp_per_capita  population\n",
      "294     USA  2002    48942.492140   284207485\n",
      "295     USA  2003    47607.365171   277711486\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "from dask_sql import Context\n",
    "df = dd.read_csv('data/data.csv')\n",
    "\n",
    "c = Context()\n",
    "c.create_table(\"dask\", df)\n",
    "print(c.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM dask\n",
    "    WHERE gdp_per_capita BETWEEN 10000 AND 50000\n",
    "        AND year BETWEEN 2000 and 2020\n",
    "    ORDER BY gdp_per_capita DESC\n",
    "    LIMIT 2\n",
    "\"\"\").compute()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "### Question 08: Dask SQL with Aggregation\n",
    "\n",
    "Using the same `data.csv` file, write a SQL query that calculates:\n",
    "\n",
    "1. The average GDP per capita for each country\n",
    "2. The minimum and maximum years in the dataset for each country\n",
    "\n",
    "Group by country and display all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "954c2fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country  avg_gdp_per_capita  min_year  max_year\n",
      "0  Brazil         5496.292031      1945      2023\n",
      "1   India         1251.704443      1945      2023\n",
      "2      UK        27496.851363      1945      2023\n",
      "3     USA        40189.822290      1945      2023\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "print(c.sql(\"\"\"\n",
    "    SELECT country, AVG(gdp_per_capita) AS avg_gdp_per_capita, MIN(year) AS min_year, MAX(year) AS max_year\n",
    "    FROM dask\n",
    "    GROUP BY country\n",
    "\"\"\").compute()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2",
   "metadata": {},
   "source": [
    "### Question 09: Generating `requirements.txt` and `environment.yml` Files\n",
    "\n",
    "Write the commands to:\n",
    "\n",
    "1. Export your current environment's packages to a `requirements.txt` and an `environment.yml` file\n",
    "2. Show how someone else would install these exact dependencies in these two cases\n",
    "\n",
    "Explain each step with comments. It is not necessary to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your answer here.\n",
    "# create environment.yml file\n",
    "conda env export --name qtm350-quiz --file ~Desktop/environment.yml\n",
    "\n",
    "# create requirement.txt file\n",
    "!pip freeze > requirements.txt\n",
    "\n",
    "# to install back:\n",
    "# conda:\n",
    "!conda env create --file ~Desktop/environment.yml\n",
    "conda activate qtm350-quiz\n",
    "\n",
    "# pip:\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5438c",
   "metadata": {},
   "source": [
    "### Question 10: Troubleshooting a Broken Dockerfile\n",
    "\n",
    "The following Dockerfile has several errors. Identify and fix 5 issues, then explain what was wrong with each line:\n",
    "\n",
    "```dockerfile\n",
    "# Broken Dockerfile - Fix the errors\n",
    "from ubuntu\n",
    "\n",
    "RUN apt install python3 python3-pip\n",
    "RUN pip install numpy pandas\n",
    "\n",
    "COPY . .\n",
    "EXPOSE 8888\n",
    "RUN [\"python3\", \"app.py\"]\n",
    "```\n",
    "\n",
    "Write the corrected Dockerfile and list each error with its fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca358893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected file:\n",
    "# 1: need capital FROM instead of from\n",
    "FROM ubuntu\n",
    "# 2: need apt-get update \n",
    "RUN apt-get update && apt-get install python3 python3-pip\n",
    "# 3: need pip3\n",
    "RUN pip3 install numpy pandas\n",
    "# 4: need copy directions\n",
    "COPY ./app\n",
    "EXPOSE 8888\n",
    "# 5: need CMD instead of RUN\n",
    "CMD [\"python3\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de7fd8",
   "metadata": {},
   "source": [
    "### Question 11 - Writing a Dockerfile to Install Software on a Base Image\n",
    "\n",
    "Create a Dockerfile that starts from an Ubuntu image and installs the following software:\n",
    "\n",
    "- Git version 2.43.0-1ubuntu7.1\n",
    "- SQLite version 3.45.1-1ubuntu2\n",
    "\n",
    "Ensure that you specify the exact versions of the packages by checking their versions after installation. Include commands to clean up the package manager cache after installation to reduce the image size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c602292",
   "metadata": {},
   "source": [
    "#### Please write your anwer here. You can use ```dockerfile to format your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a4e9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerfile_content = \"\"\"\n",
    "FROM ubuntu\n",
    "RUN apt-get update && install git=2.43.0-1ubuntu7.1 sqlite3=3.45.1-1ubuntu2\n",
    "RUN git --version && sqlite3 --version\n",
    "RUN apt-get clean\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7354df6",
   "metadata": {},
   "source": [
    "### Question 12: Dockerfile for a Jupyter Data Science Environment\n",
    "\n",
    "Create a Dockerfile starting from Ubuntu that:\n",
    "\n",
    "1. Installs Python 3.11 and pip\n",
    "2. Installs `jupyterlab`, `numpy`, `pandas`, `matplotlib`, and `scikit-learn` with specific versions of your choice\n",
    "4. Sets the working directory to `/home/analyst/notebooks`\n",
    "5. Exposes port 8888\n",
    "6. Starts JupyterLab with `--no-browser` and `--ip=0.0.0.0`\n",
    "\n",
    "Clean up apt cache to reduce image size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9c49e",
   "metadata": {},
   "source": [
    "#### Please write your answer here. You can use ```dockerfile to format your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5463e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I made up fake version numbers\n",
    "dockerfile_content = \"\"\"\n",
    "FROM ubuntu\n",
    "RUN apt-get update && apt-get install -y python3.11 python-3pip\n",
    "RUN pip3 install jupyterlab==5.0.0, numpy-5.0.0, pandas=5.0.0, matplotlib=5.0.0, scikit-learn=5.0.0\n",
    "WORKDIR /home/analyst/notebooks\n",
    "EXPOSE 8888\n",
    "CMD [\"jupyter\", \"lab\", \"--no-browser\", \"--ip=0.0.0.0]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtm350-quiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
